#! /usr/bin/python

import sys
from pyquery import PyQuery
import urllib
import re

args = sys.argv[1:]
progress_file = '.mget'

if len(args) <= 1:
	with open(progress_file) as f:
    		file_str = f.read()
    		args = file_str.split('\n')

base_url = args[0]
page_url = base_url + args[1]
img_selector = args[2]
next_page_selector = args[3]
naming_regex = args[4]
ext_regex = r".*(\..+)"

naming_e = re.compile(naming_regex)
ext_e = re.compile(ext_regex)

while page_url:
	pq = PyQuery(url=page_url)
	img_tag = pq(img_selector)
	next_page_tag = pq(next_page_selector)
	m = naming_e.search(page_url)

	img_url = ''
	page_url = ''
	name = ''
	if (len(img_tag) > 0 and len(next_page_tag) > 0 and m):
		name = m.group('chapter').strip()
		if(m.group('page')):
			name += "-" + m.group('page').strip()
		img_url = pq(img_tag).attr('src')
		m2 = ext_e.search(img_url)
		if(m2.group(1)):
			name += m2.group(1).strip()
		args[1] = pq(next_page_tag).attr('href')
		page_url = base_url + args[1]
		urllib.urlretrieve(img_url, name)

		print name + ' downloaded'

		with open(progress_file, "w") as f:
    			f.write('\n'.join(args))
